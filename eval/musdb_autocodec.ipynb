{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3b6a3b0-bc00-4ec5-b0b2-3dc34104bfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi --query-gpu=name --format=csv,noheader | head -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d7db02c-516f-4ddd-ba4a-31b7dcc18526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import PIL\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "import einops\n",
    "from IPython.display import Audio\n",
    "from types import SimpleNamespace\n",
    "from torchvision.transforms import ToPILImage, PILToTensor\n",
    "from datasets import load_dataset, Image\n",
    "from autocodec.codec import AutoCodecND, latent_to_pil, pil_to_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eea68b9d-1e5a-432f-af4a-8ad4447fcf3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de071842da9641ef988fe471cf329500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebafa2fa48684f7886cfd1e4fcb622c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b49b73da7e324a629ebf1c69784f91fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3662f9f934574901880ba744e883afd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae38ba01a1ae46db9b78d9ff4efe86ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MUSDB = load_dataset(\"danjacobellis/musdb_segments\", split='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37a32ba4-7389-4f20-9887-ed52c042dc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "checkpoint = torch.load('../../hf/autocodec/musdb_stereo_f512c16.pth', map_location=\"cpu\",weights_only=False)\n",
    "config = checkpoint['config']\n",
    "state_dict = checkpoint['state_dict']\n",
    "model = AutoCodecND(\n",
    "    dim=1,\n",
    "    input_channels=config.input_channels,\n",
    "    J = int(np.log2(config.F)),\n",
    "    latent_dim=config.latent_dim,\n",
    "    encoder_depth = config.encoder_depth,\n",
    "    encoder_kernel_size = config.encoder_kernel_size,\n",
    "    decoder_depth = config.decoder_depth,\n",
    "    lightweight_encode = config.lightweight_encode,\n",
    "    lightweight_decode = config.lightweight_decode,\n",
    ").to(device).to(torch.bfloat16)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8024e4dc-ba66-4c7c-a543-642a0e45c33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(audio, p=2**16):\n",
    "    B,C,L = audio.shape\n",
    "    padding_size = (p - (L % p)) % p\n",
    "    if padding_size > 0:\n",
    "        audio = torch.nn.functional.pad(audio, (0, padding_size), mode='constant', value=0)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "021b474e-b622-49da-b074-d426d754b124",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autocodec_compress(sample):\n",
    "    with torch.no_grad():\n",
    "        x, fs = torchaudio.load(sample['audio_mix']['bytes'],normalize=False)\n",
    "        x = x.to(torch.float)\n",
    "        x = x - x.mean()\n",
    "        max_abs = x.abs().max()\n",
    "        x = x / (max_abs + 1e-8)\n",
    "        x = x/2\n",
    "        L = x.shape[-1]\n",
    "    \n",
    "        t0 = time.time()\n",
    "        x_padded = pad(x.unsqueeze(0), 2**16).to(device).to(torch.bfloat16)\n",
    "        z = model.encode(x_padded)\n",
    "        latent = model.quantize.compand(z).round().cpu()\n",
    "        latent_reshaped = einops.rearrange(latent, 'b c (h w) -> b c h w', h=32)\n",
    "        latent_img = latent_to_pil(latent_reshaped, n_bits=8, C=4)\n",
    "        buff = io.BytesIO()\n",
    "        latent_img[0].save(buff, format='TIFF', compression='tiff_adobe_deflate')\n",
    "        tiff_bytes = buff.getbuffer()\n",
    "        encode_time = time.time() - t0\n",
    "        t0 = time.time()\n",
    "        latent_decoded = pil_to_latent([PIL.Image.open(buff)], N=16, n_bits=8, C=4)\n",
    "        latent_decoded = einops.rearrange(latent_decoded, 'b c h w -> b c (h w)')\n",
    "        x_hat = model.decode(latent_decoded.to(device).to(torch.bfloat16))\n",
    "        x_hat = x_hat.clamp(-1,1)\n",
    "        decode_time = time.time() - t0\n",
    "        x_hat = x_hat.to(\"cpu\").to(torch.float)[0]\n",
    "        CR = x.numel()/len(tiff_bytes)\n",
    "        mse = torch.nn.functional.mse_loss(x,x_hat)\n",
    "        PSNR = -10*mse.log10().item() + 6.02\n",
    "        \n",
    "    return {\n",
    "        'compressed': tiff_bytes,\n",
    "        'encode_time': encode_time,\n",
    "        'decode_time': decode_time,\n",
    "        'CR': CR,\n",
    "        'L': L,\n",
    "        'PSNR': PSNR,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ff8eb8f0-43f8-46bc-8418-62c9f207caa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20330c67affe44e0ba6bdd44305a871b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/262 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "model = model.to(device)\n",
    "gpu = MUSDB.map(\n",
    "    autocodec_compress,\n",
    "    writer_batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f58c9ef6-d925-48a0-81e3-4d4f029f892d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encode_time: 0.011013405013630408\n",
      "decode_time: 0.005401287370055686\n",
      "CR: 194.48654358290898\n",
      "PSNR: 36.56908681461829\n"
     ]
    }
   ],
   "source": [
    "for metric in ['encode_time','decode_time','CR','PSNR']:\n",
    "    μ = np.mean(gpu[metric])\n",
    "    print(f\"{metric}: {μ}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5a9dd592-ac3c-472f-aecd-fca0209192a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(199.2718)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.tensor(gpu['L'])/torch.tensor(gpu['encode_time'])).mean()/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ef722295-4755-4753-9682-2ec035e2b31e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(414.9786)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.tensor(gpu['L'])/torch.tensor(gpu['decode_time'])).mean()/1e6"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
