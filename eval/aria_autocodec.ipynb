{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d7db02c-516f-4ddd-ba4a-31b7dcc18526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import PIL\n",
    "import torchaudio\n",
    "import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import einops\n",
    "from IPython.display import Audio\n",
    "from types import SimpleNamespace\n",
    "from torchvision.transforms.v2 import CenterCrop\n",
    "from autocodec.codec import AutoCodecND, latent_to_pil, pil_to_latent\n",
    "from IPython.display import Audio as play\n",
    "from spauq.core.metrics import spauq_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12230ef2-5459-483f-967c-5cb734c5774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(audio, p=2**16):\n",
    "    B, C, L = audio.shape\n",
    "    padding_size = (p - (L % p)) % p\n",
    "    if padding_size > 0:\n",
    "        left_pad = padding_size // 2\n",
    "        right_pad = padding_size - left_pad\n",
    "        audio = torch.nn.functional.pad(audio, (left_pad, right_pad), mode='constant', value=0)\n",
    "    return audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eea68b9d-1e5a-432f-af4a-8ad4447fcf3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7b2a12542f4ef38f3b2a5a07048b5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63daace7f9e74e169596049c8093b1bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(\"danjacobellis/aria_ea_audio_preprocessed\").with_format(\"numpy\",dtype='float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37a32ba4-7389-4f20-9887-ed52c042dc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "checkpoint = torch.load('../../hf/autocodec/aria_7ch_f128c28.pth', map_location=\"cpu\",weights_only=False)\n",
    "config = checkpoint['config']\n",
    "state_dict = checkpoint['state_dict']\n",
    "model = AutoCodecND(\n",
    "    dim=1,\n",
    "    input_channels=config.input_channels,\n",
    "    J = int(np.log2(config.F)),\n",
    "    latent_dim=config.latent_dim,\n",
    "    encoder_depth = config.encoder_depth,\n",
    "    encoder_kernel_size = config.encoder_kernel_size,\n",
    "    decoder_depth = config.decoder_depth,\n",
    "    lightweight_encode = config.lightweight_encode,\n",
    "    lightweight_decode = config.lightweight_decode,\n",
    ").to(device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(torch.bfloat16)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f58eac5e-463e-45ba-b5dd-8486485f7807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_quality(sample):\n",
    "\n",
    "    x = torch.tensor(sample['audio']).permute(1,0)\n",
    "    L = x.shape[-1]\n",
    "    \n",
    "    t0 = time.time()\n",
    "    x_padded = pad(x.unsqueeze(0), config.F*32).to(device).to(torch.bfloat16)\n",
    "    with torch.no_grad():\n",
    "        z = model.quantize.compand(model.encode(x_padded)).round().cpu()\n",
    "    img_list = latent_to_pil(\n",
    "        einops.rearrange(z,'b c (h w) -> c b h w', h=32),n_bits=16,C=1)\n",
    "    buff_list = []\n",
    "    for img in img_list:\n",
    "        buff_list.append(io.BytesIO())\n",
    "        img.save(buff_list[-1], format='TIFF', compression='tiff_adobe_deflate')\n",
    "    encode_time = time.time() - t0\n",
    "    \n",
    "    cr = 2*x.numel()/sum(len(b.getbuffer()) for b in buff_list)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    zhat = pil_to_latent([PIL.Image.open(b) for b in buff_list], N=1, n_bits=8, C=1)\n",
    "    zhat = z.clone().to(device).to(torch.bfloat16)\n",
    "    with torch.no_grad():\n",
    "        xhat = model.decode(zhat)\n",
    "    xhat = xhat.clamp(-1,1)\n",
    "    decode_time = time.time() - t0\n",
    "    \n",
    "    xhat = xhat.to(\"cpu\").to(torch.float)\n",
    "    xhat = CenterCrop((config.input_channels,x.shape[1]))(xhat)[0]\n",
    "    mse = torch.nn.functional.mse_loss(x,xhat)\n",
    "    psnr = -10*mse.log10().item() + 6.02\n",
    "    \n",
    "    SDR = spauq_eval(x.to(torch.float),xhat.to(\"cpu\"),fs=48000)\n",
    "    ssdr = SDR['SSR']\n",
    "    srdr = SDR['SRR']\n",
    "\n",
    "    return {\n",
    "        'samples': x.numel(),\n",
    "        'cr': cr,\n",
    "        'encode_time': encode_time,\n",
    "        'decode_time': decode_time,\n",
    "        'psnr': psnr,\n",
    "        'ssdr': ssdr,\n",
    "        'srdr': srdr,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73e36552-f567-4118-a241-44efb9f65061",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    'samples',\n",
    "    'cr',\n",
    "    'encode_time',\n",
    "    'decode_time',\n",
    "    'psnr',\n",
    "    'ssdr',\n",
    "    'srdr',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d62f88b6-6680-49d2-bfbd-65e876ed20fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_results = dataset['validation'].select(range(10)).map(evaluate_quality).with_format(\"torch\",dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa16d6e3-5d46-4a41-a2c5-8a1150e19534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\n",
      "---\n",
      "samples: 2100000.0\n",
      "cr: 1013.5135498046875\n",
      "encode_time: 0.006712436676025391\n",
      "decode_time: 0.009349226951599121\n",
      "psnr: 30.780847549438477\n",
      "ssdr: 11.865995407104492\n",
      "srdr: 4.528044700622559\n",
      "328.0713806152344 MS/sec\n",
      "252.41958618164062 MS/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3809360/4291437718.py:5: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  print(f\"{np.mean(np.array(gpu_results['samples'])/1e6/np.array(gpu_results['encode_time']))} MS/sec\")\n",
      "/tmp/ipykernel_3809360/4291437718.py:6: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  print(f\"{np.mean(np.array(gpu_results['samples'])/1e6/np.array(gpu_results['decode_time']))} MS/sec\")\n"
     ]
    }
   ],
   "source": [
    "print(\"mean\\n---\")\n",
    "for metric in metrics:\n",
    "    μ = gpu_results[metric].mean()\n",
    "    print(f\"{metric}: {μ}\")\n",
    "print(f\"{np.mean(np.array(gpu_results['samples'])/1e6/np.array(gpu_results['encode_time']))} MS/sec\")\n",
    "print(f\"{np.mean(np.array(gpu_results['samples'])/1e6/np.array(gpu_results['decode_time']))} MS/sec\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
