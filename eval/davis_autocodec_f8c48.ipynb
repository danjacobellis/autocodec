{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31802a5a-cddf-4ebd-9d87-2aca01836585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import PIL.Image\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datasets\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "from timm.optim import Mars\n",
    "from types import SimpleNamespace\n",
    "from IPython.display import HTML\n",
    "from types import SimpleNamespace\n",
    "from fastprogress import progress_bar, master_bar\n",
    "from torchvision.transforms.v2 import CenterCrop, RandomCrop\n",
    "from torchvision.transforms.v2.functional import pil_to_tensor, to_pil_image\n",
    "from decord import VideoReader\n",
    "from autocodec.codec import AutoCodecND, latent_to_pil, pil_to_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "550eece5-fccd-4fba-ba81-f81f73a3fd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "dataset = datasets.load_dataset(\"danjacobellis/davis\").cast_column('video',datasets.Video()).with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "212dc070-e81c-46ae-a394-b476d4010a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('../../hf/autocodec/video_f8c48.pth', map_location=\"cpu\",weights_only=False)\n",
    "\n",
    "config = checkpoint['config']\n",
    "state_dict = checkpoint['state_dict']\n",
    "model = AutoCodecND(\n",
    "    dim=3,\n",
    "    input_channels=config.input_channels,\n",
    "    J = int(np.log2(config.F)),\n",
    "    latent_dim=config.latent_dim,\n",
    "    encoder_depth = config.encoder_depth,\n",
    "    encoder_kernel_size = config.encoder_kernel_size,\n",
    "    decoder_depth = config.decoder_depth,\n",
    "    lightweight_encode = config.lightweight_encode,\n",
    "    lightweight_decode = config.lightweight_decode,\n",
    ").to(device).to(torch.bfloat16)\n",
    "model.load_state_dict(state_dict)\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdb2bf0e-b731-4c11-9201-ac26cbf1a486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad3d(x, p, extra, small_dim_mode):\n",
    "    b, c, f, h, w = x.shape\n",
    "    extra_f, extra_h, extra_w = extra  # Unpack the extra tuple for each dimension\n",
    "    \n",
    "    for dim, size, extra_pad in zip(['f', 'h', 'w'], [f, h, w], [extra_f, extra_h, extra_w]):\n",
    "        if small_dim_mode and size < p:\n",
    "            pad1 = extra_pad\n",
    "            pad2 = extra_pad\n",
    "        else:\n",
    "            t = math.ceil(size / p) * p\n",
    "            pad_total = t - size\n",
    "            pad1 = pad_total // 2\n",
    "            pad2 = pad_total - pad1\n",
    "            pad1 += extra_pad\n",
    "            pad2 += extra_pad\n",
    "        if dim == 'f':\n",
    "            fp1, fp2 = pad1, pad2\n",
    "        elif dim == 'h':\n",
    "            hp1, hp2 = pad1, pad2\n",
    "        elif dim == 'w':\n",
    "            wp1, wp2 = pad1, pad2\n",
    "            \n",
    "    return torch.nn.functional.pad(\n",
    "        x,\n",
    "        pad=(wp1, wp2, hp1, hp2, fp1, fp2),\n",
    "        mode=\"reflect\"\n",
    "    )\n",
    "\n",
    "def center_crop_3d(x, f, h, w):\n",
    "    assert x.ndim == 5\n",
    "    _, _, F, H, W = x.shape\n",
    "    front = (F - f) // 2\n",
    "    back  = front + f\n",
    "    top   = (H - h) // 2\n",
    "    bottom = top + h\n",
    "    left  = (W - w) // 2\n",
    "    right = left + w\n",
    "    return x[:, :, front:back, top:bottom, left:right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24b72a7-8f04-40ec-8556-de62e892d93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='71' class='' max='90' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      78.89% [71/90 25:52&lt;06:55 PSNR: 27.038517441860463, CR:56.47795666709316]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_w = 1920\n",
    "target_h = 1080\n",
    "PSNR_list = []\n",
    "CR_list = []\n",
    "pb = progress_bar(dataset['train'])\n",
    "encode_time = 0\n",
    "decode_time = 0\n",
    "total_frames = 0\n",
    "for sample in pb:\n",
    "    \n",
    "    video = sample['video']\n",
    "    len_video = len(video)\n",
    "    total_frames += len_video\n",
    "    xr = video.get_batch(range(len_video))\n",
    "    xr = einops.rearrange(xr, 'f h w c -> c f h w')\n",
    "    x = []\n",
    "    for i_frame in range(len_video):\n",
    "        frame = xr[:, i_frame]\n",
    "        pil_img = to_pil_image(frame)\n",
    "        resized_img = pil_img.resize((target_w, target_h))\n",
    "        tensor_frame = pil_to_tensor(resized_img).unsqueeze(1)\n",
    "        x.append(tensor_frame)\n",
    "    x = torch.cat(x, dim=1).unsqueeze(0)\n",
    "    x = x / 127.5 - 1.0\n",
    "    x = x.to(device).to(torch.bfloat16)\n",
    "    x_orig = x.clone()\n",
    "    x = pad3d(x, p=config.F, extra=(8,0,0), small_dim_mode=True)\n",
    "    # encode\n",
    "    with torch.no_grad():\n",
    "        t0 = time.time()\n",
    "        z = model.encode(x)\n",
    "        latent = model.quantize.compand(z).round().to(torch.bfloat16)\n",
    "        dt = time.time() - t0\n",
    "        encode_time += dt\n",
    "\n",
    "    # decode\n",
    "    x_hat = []\n",
    "    for i_chunk in range(latent.shape[2]-2):\n",
    "        i1 = i_chunk; i2 = i_chunk+3\n",
    "        latent_chunk = latent[:,:,i1:i2,:,:]\n",
    "        with torch.no_grad():\n",
    "            t0 = time.time()\n",
    "            x_hat.append(model.decode(latent_chunk)[:,:,8:16].clamp(-1,1))\n",
    "            dt = time.time() - t0\n",
    "            decode_time += dt\n",
    "    x_hat = torch.cat(x_hat,dim=2)\n",
    "    \n",
    "    _,_,f,h,w = x_orig.shape\n",
    "    x_hat = center_crop_3d(x_hat,f,h,w)\n",
    "    \n",
    "    x_orig_01 = x_orig / 2 + 0.5\n",
    "    x_hat_01 = x_hat / 2 + 0.5\n",
    "    PSNR = []\n",
    "    for i_frame in range(x_orig_01.shape[2]):\n",
    "        mse = torch.nn.functional.mse_loss(x_orig_01[0, :, i_frame], x_hat_01[0, :, i_frame])\n",
    "        PSNR.append(-10 * mse.log10().item())\n",
    "    PSNR_list.append(PSNR)\n",
    "    \n",
    "    size_bytes = 0\n",
    "    t0 = time.time()\n",
    "    for chunk in latent_to_pil(einops.rearrange(latent[0], 'c f h w -> f c h w').cpu(),n_bits=8,C=3):\n",
    "        buff = io.BytesIO()\n",
    "        chunk.save(buff,format='webp',lossless=True)\n",
    "        size_bytes += len(buff.getbuffer())\n",
    "    dt = time.time() - t0\n",
    "    encode_time += dt\n",
    "    CR_list.append(x_orig.numel()/size_bytes)\n",
    "\n",
    "    pb.comment = (f\"PSNR: {np.mean(PSNR)}, CR:{CR_list[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cabfc50-c981-4246-aa45-28f3c0398bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(25.7921875)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min([np.mean(per_frame_psnr) for per_frame_psnr in PSNR_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8010db97-fe2d-4439-b308-2a775aba7c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(30.241360876081732)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([np.mean(per_frame_psnr) for per_frame_psnr in PSNR_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be5ecb9f-e871-4e60-bccd-bb41e4c4c160",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(40.760690789473685)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max([np.mean(per_frame_psnr) for per_frame_psnr in PSNR_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c728e156-e28a-4cb6-bbfc-3ad2d4fee172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.606962237145176"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_frames/encode_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "64d4212c-295f-4afc-a5d9-bf2fd8a243cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.8869175532133635"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_frames/decode_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab8e887b-df3a-4a50-8ec3-465b6327cbfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(65)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax([np.mean(per_frame_psnr) for per_frame_psnr in PSNR_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99164214-873e-4a7f-9fc4-938f4a5c3bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(63)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin([np.mean(per_frame_psnr) for per_frame_psnr in PSNR_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3ce2197-3862-4a5a-8e4d-94eb58562001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(79.60111699678902)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(CR_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eed4048-3728-4829-a740-867a178d0fa1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1a951f-95b1-430f-9fc7-b964b198884b",
   "metadata": {},
   "outputs": [],
   "source": [
    "video = dataset['train'][70]['video']\n",
    "len_video = len(video)\n",
    "total_frames += len_video\n",
    "xr = video.get_batch(range(len_video))\n",
    "xr = einops.rearrange(xr, 'f h w c -> c f h w')\n",
    "x = []\n",
    "for i_frame in range(len_video):\n",
    "    frame = xr[:, i_frame]\n",
    "    pil_img = to_pil_image(frame)\n",
    "    resized_img = pil_img.resize((target_w, target_h))\n",
    "    tensor_frame = pil_to_tensor(resized_img).unsqueeze(1)\n",
    "    x.append(tensor_frame)\n",
    "x = torch.cat(x, dim=1).unsqueeze(0)\n",
    "x = x / 127.5 - 1.0\n",
    "x = x.to(device).to(torch.bfloat16)\n",
    "x_orig = x.clone()\n",
    "x = pad3d(x, p=config.F, extra=(8,0,0), small_dim_mode=True)\n",
    "# encode\n",
    "with torch.no_grad():\n",
    "    t0 = time.time()\n",
    "    z = model.encode(x)\n",
    "    latent = model.quantize.compand(z).round().to(torch.bfloat16)\n",
    "    dt = time.time() - t0\n",
    "    encode_time += dt\n",
    "\n",
    "# decode\n",
    "x_hat = []\n",
    "for i_chunk in range(latent.shape[2]-2):\n",
    "    i1 = i_chunk; i2 = i_chunk+3\n",
    "    latent_chunk = latent[:,:,i1:i2,:,:]\n",
    "    with torch.no_grad():\n",
    "        t0 = time.time()\n",
    "        x_hat.append(model.decode(latent_chunk)[:,:,8:16].clamp(-1,1))\n",
    "        dt = time.time() - t0\n",
    "        decode_time += dt\n",
    "x_hat = torch.cat(x_hat,dim=2)\n",
    "\n",
    "_,_,f,h,w = x_orig.shape\n",
    "x_hat = center_crop_3d(x_hat,f,h,w)\n",
    "\n",
    "x_orig_01 = x_orig / 2 + 0.5\n",
    "x_hat_01 = x_hat / 2 + 0.5\n",
    "PSNR = []\n",
    "for i_frame in range(x_orig_01.shape[2]):\n",
    "    mse = torch.nn.functional.mse_loss(x_orig_01[0, :, i_frame], x_hat_01[0, :, i_frame])\n",
    "    PSNR.append(-10 * mse.log10().item())\n",
    "\n",
    "size_bytes = 0\n",
    "t0 = time.time()\n",
    "for chunk in latent_to_pil(einops.rearrange(latent[0], 'c f h w -> f c h w').cpu(),n_bits=8,C=3):\n",
    "    buff = io.BytesIO()\n",
    "    chunk.save(buff,format='webp',lossless=True)\n",
    "    size_bytes += len(buff.getbuffer())\n",
    "dt = time.time() - t0\n",
    "encode_time += dt\n",
    "x_orig.numel()/size_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf191b02-5413-4e20-a270-6701dc60c50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(PSNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59be9512-324d-4999-b5cf-591deab2e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6d192693-41eb-45e2-83e3-1b2122ee813d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 4.4.2-0ubuntu0.22.04.1+esm6 Copyright (c) 2000-2021 the FFmpeg developers\n",
      "  built with gcc 11 (Ubuntu 11.4.0-1ubuntu1~22.04)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.22.04.1+esm6 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --arch=amd64 --enable-gpl --disable-stripping --enable-gnutls --enable-ladspa --enable-libaom --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libcodec2 --enable-libdav1d --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libjack --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librabbitmq --enable-librubberband --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libsrt --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvidstab --enable-libvorbis --enable-libvpx --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzimg --enable-libzmq --enable-libzvbi --enable-lv2 --enable-omx --enable-openal --enable-opencl --enable-opengl --enable-sdl2 --enable-pocketsphinx --enable-librsvg --enable-libmfx --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libx264 --enable-shared\n",
      "  libavutil      56. 70.100 / 56. 70.100\n",
      "  libavcodec     58.134.100 / 58.134.100\n",
      "  libavformat    58. 76.100 / 58. 76.100\n",
      "  libavdevice    58. 13.100 / 58. 13.100\n",
      "  libavfilter     7.110.100 /  7.110.100\n",
      "  libswscale      5.  9.100 /  5.  9.100\n",
      "  libswresample   3.  9.100 /  3.  9.100\n",
      "  libpostproc    55.  9.100 / 55.  9.100\n",
      "Input #0, image2, from 'test/frame_%04d.jpg':\n",
      "  Duration: 00:00:03.63, start: 0.000000, bitrate: N/A\n",
      "  Stream #0:0: Video: mjpeg (Baseline), yuvj420p(pc, bt470bg/unknown/unknown), 1920x1080 [SAR 1:1 DAR 16:9], 24 fps, 24 tbr, 24 tbn, 24 tbc\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (mjpeg (native) -> mjpeg (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, avi, to 'output_mjpeg.avi':\n",
      "  Metadata:\n",
      "    ISFT            : Lavf58.76.100\n",
      "  Stream #0:0: Video: mjpeg (MJPG / 0x47504A4D), yuvj420p(pc, bt470bg/unknown/unknown, progressive), 1920x1080 [SAR 1:1 DAR 16:9], q=2-31, 200 kb/s, 24 fps, 24 tbn\n",
      "    Metadata:\n",
      "      encoder         : Lavc58.134.100 mjpeg\n",
      "    Side data:\n",
      "      cpb: bitrate max/min/avg: 0/0/200000 buffer size: 0 vbv_delay: N/A\n",
      "frame=   87 fps=0.0 q=1.0 Lsize=   20331kB time=00:00:03.62 bitrate=45945.5kbits/s speed=4.08x    \n",
      "video:20323kB audio:0kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: 0.037864%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['ffmpeg', '-y', '-framerate', '24', '-i', 'test/frame_%04d.jpg', '-c:v', 'mjpeg', '-q:v', '1', 'output_mjpeg.avi'], returncode=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "output_dir = 'test'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "num_frames = x_hat.shape[2]\n",
    "for i_frame in range(num_frames):\n",
    "    img = to_pil_image(x_hat[0, :, i_frame].to(torch.float) / 2 + 0.5)\n",
    "    filename = os.path.join(output_dir, f\"frame_{i_frame:04d}.jpg\")\n",
    "    img.save(filename, format=\"jpeg\", quality=100)\n",
    "output_video = 'output_mjpeg.avi'\n",
    "ffmpeg_cmd = [\n",
    "    'ffmpeg',\n",
    "    '-y', \n",
    "    '-framerate', '24',\n",
    "    '-i', os.path.join(output_dir, 'frame_%04d.jpg'),\n",
    "    '-c:v', 'mjpeg',\n",
    "    '-q:v', '1',\n",
    "    output_video\n",
    "]\n",
    "subprocess.run(ffmpeg_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914b56aa-df92-4639-bb19-b2dd6c3aaa56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
