{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31802a5a-cddf-4ebd-9d87-2aca01836585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import PIL.Image\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datasets\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "from timm.optim import Mars\n",
    "from types import SimpleNamespace\n",
    "from IPython.display import HTML\n",
    "from types import SimpleNamespace\n",
    "from fastprogress import progress_bar, master_bar\n",
    "from torchvision.transforms.v2 import CenterCrop, RandomCrop\n",
    "from torchvision.transforms.v2.functional import pil_to_tensor, to_pil_image\n",
    "from decord import VideoReader\n",
    "from autocodec.codec import AutoCodecND, latent_to_pil, pil_to_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "550eece5-fccd-4fba-ba81-f81f73a3fd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "medmnist_types = ['organ', 'adrenal', 'fracture', 'nodule', 'synapse', 'vessel']\n",
    "dataset_train = datasets.concatenate_datasets([datasets.load_dataset(f\"danjacobellis/{type}mnist3d_64\", split='train') for type in medmnist_types])\n",
    "dataset_valid = datasets.concatenate_datasets([datasets.load_dataset(f\"danjacobellis/{type}mnist3d_64\", split='validation') for type in medmnist_types])\n",
    "dataset = datasets.DatasetDict({\n",
    "    'train': dataset_train,\n",
    "    'validation': dataset_valid\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "212dc070-e81c-46ae-a394-b476d4010a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('../../hf/autocodec/med3d_f8c8.pth', map_location=\"cpu\",weights_only=False)\n",
    "\n",
    "config = checkpoint['config']\n",
    "state_dict = checkpoint['state_dict']\n",
    "model = AutoCodecND(\n",
    "    dim=3,\n",
    "    input_channels=config.input_channels,\n",
    "    J = int(np.log2(config.F)),\n",
    "    latent_dim=config.latent_dim,\n",
    "    encoder_depth = config.encoder_depth,\n",
    "    encoder_kernel_size = config.encoder_kernel_size,\n",
    "    decoder_depth = config.decoder_depth,\n",
    "    lightweight_encode = config.lightweight_encode,\n",
    "    lightweight_decode = config.lightweight_decode,\n",
    ").to(device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.to(torch.bfloat16)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cde27fb-c2a8-44a6-b4d0-c59352f095ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pil_to_grid3d(img):\n",
    "    x = torch.tensor(np.array(img))\n",
    "    x = einops.rearrange(x, '(a y) (b z) c -> (a b c) y z', a=4, b=4, c=4)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "396aedf6-8714-43bc-8bda-2be57cb7ec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_quality(sample):\n",
    "    \n",
    "    x = pil_to_grid3d(sample['image']).unsqueeze(0).unsqueeze(0).to(device).to(torch.bfloat16) / 127.5 - 1.0\n",
    "    orig_dim = x.numel()\n",
    "    \n",
    "    t0 = time.time()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x)\n",
    "        latent = model.quantize.compand(z).round()\n",
    "    latent = einops.rearrange(latent, 'b c d h w -> b (c d) h w').cpu()\n",
    "    img = latent_to_pil(latent, n_bits=8, C=4)\n",
    "    buff = io.BytesIO()\n",
    "    img[0].save(buff, format='TIFF', compression = 'tiff_adobe_deflate')\n",
    "    encode_time = time.time() - t0\n",
    "    \n",
    "    size_bytes = len(buff.getbuffer())\n",
    "    cr = x.numel()/size_bytes\n",
    "    \n",
    "    t0 = time.time()\n",
    "    latent_decoded = pil_to_latent([PIL.Image.open(buff)], N=64, n_bits=8, C=4)\n",
    "    latent_decoded = einops.rearrange(latent_decoded, 'b (c d) h w -> b c d h w', d=8).to(device).to(torch.bfloat16)\n",
    "    with torch.no_grad():\n",
    "        x_hat = model.decode(latent_decoded).clamp(-1, 1)\n",
    "    decode_time = time.time() - t0\n",
    "    \n",
    "    \n",
    "    mse = torch.nn.functional.mse_loss(x, x_hat)\n",
    "    psnr = -10 * mse.log10().item() + 6.02\n",
    "\n",
    "    return {\n",
    "        'voxels': x.numel(),\n",
    "        'cr': cr,\n",
    "        'encode_time': encode_time,\n",
    "        'decode_time': decode_time,\n",
    "        'psnr': psnr\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8833632-bc32-49cf-862b-ef456dbf57e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "783a864f28d845c7a3096c833b6695dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/895 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gpu_results = dataset['validation'].map(evaluate_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "332b25b1-342e-4ec1-886c-a66db365bc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    'voxels',\n",
    "    'encode_time',\n",
    "    'decode_time',\n",
    "    'cr',\n",
    "    'psnr',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a70e5cc0-7af6-468c-9ed2-957c7eb56e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\n",
      "---\n",
      "voxels: 262144.0\n",
      "encode_time: 0.005050100560960823\n",
      "decode_time: 0.004511122197412246\n",
      "cr: 209.2325504413078\n",
      "psnr: 24.740452164804466\n",
      "54.07623692142692 MVox/sec\n",
      "59.76341054905106 MVox/sec\n"
     ]
    }
   ],
   "source": [
    "print(\"mean\\n---\")\n",
    "for metric in metrics:\n",
    "    μ = np.mean(gpu_results[metric])\n",
    "    print(f\"{metric}: {μ}\")\n",
    "print(f\"{np.mean(np.array(gpu_results['voxels'])/1e6/np.array(gpu_results['encode_time']))} MVox/sec\")\n",
    "print(f\"{np.mean(np.array(gpu_results['voxels'])/1e6/np.array(gpu_results['decode_time']))} MVox/sec\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
