{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d85e1e44-a706-49f7-b752-377bc99f00be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-04-14 14:36:09--  https://huggingface.co/danjacobellis/dance/resolve/main/lsdir_ft_rgb_f16c12.pth\n",
      "Resolving huggingface.co (huggingface.co)... 99.86.102.115, 99.86.102.9, 99.86.102.128, ...\n",
      "Connecting to huggingface.co (huggingface.co)|99.86.102.115|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cdn-lfs-us-1.hf.co/repos/d8/1e/d81e83e7bf11bcd7e71f3a8e05ae4eaab4f578a5377b018a767bd640ffcc0f0f/60287be8ff53f064f2f65afcb3fb5e0d382bfeecbaf2f4c4a14b29eed892fb4a?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27lsdir_ft_rgb_f16c12.pth%3B+filename%3D%22lsdir_ft_rgb_f16c12.pth%22%3B&Expires=1744641369&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NDY0MTM2OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2Q4LzFlL2Q4MWU4M2U3YmYxMWJjZDdlNzFmM2E4ZTA1YWU0ZWFhYjRmNTc4YTUzNzdiMDE4YTc2N2JkNjQwZmZjYzBmMGYvNjAyODdiZThmZjUzZjA2NGYyZjY1YWZjYjNmYjVlMGQzODJiZmVlY2JhZjJmNGM0YTE0YjI5ZWVkODkyZmI0YT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=YYIsky2E3uYu%7EnVwT4jjFuNoOdyIN%7EOAKjZrI8KFFJjVvRijHw0rCdXqVslakWp1YT67riFFClASzqy%7EUL7AJRmbaSu7r6hHmexmVPwedQZCKET2euhccILtBG9B4g0%7E8TZAhaU4Zfq6Uur-D9tVmtIzKVfqgLY9sYVJbyfXf0bg4g4g-7bBS5cjLIzdztvjxR4-y%7EXUCeYWJkJ-alD-kUGM7-oz9Mcd6VX9axM1yj%7EtFqtSeWFw5XBRxeq8OMGFKM%7EaYqQInElus5VR3HhUe0DS4S4OSTKSkApblo2zN9tgYF-3Q08JaYMkTGNoNzQJ1upVklbfk7QYYfzkWEsHbg__&Key-Pair-Id=K24J24Z295AEI9 [following]\n",
      "--2025-04-14 14:36:10--  https://cdn-lfs-us-1.hf.co/repos/d8/1e/d81e83e7bf11bcd7e71f3a8e05ae4eaab4f578a5377b018a767bd640ffcc0f0f/60287be8ff53f064f2f65afcb3fb5e0d382bfeecbaf2f4c4a14b29eed892fb4a?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27lsdir_ft_rgb_f16c12.pth%3B+filename%3D%22lsdir_ft_rgb_f16c12.pth%22%3B&Expires=1744641369&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NDY0MTM2OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2Q4LzFlL2Q4MWU4M2U3YmYxMWJjZDdlNzFmM2E4ZTA1YWU0ZWFhYjRmNTc4YTUzNzdiMDE4YTc2N2JkNjQwZmZjYzBmMGYvNjAyODdiZThmZjUzZjA2NGYyZjY1YWZjYjNmYjVlMGQzODJiZmVlY2JhZjJmNGM0YTE0YjI5ZWVkODkyZmI0YT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=YYIsky2E3uYu%7EnVwT4jjFuNoOdyIN%7EOAKjZrI8KFFJjVvRijHw0rCdXqVslakWp1YT67riFFClASzqy%7EUL7AJRmbaSu7r6hHmexmVPwedQZCKET2euhccILtBG9B4g0%7E8TZAhaU4Zfq6Uur-D9tVmtIzKVfqgLY9sYVJbyfXf0bg4g4g-7bBS5cjLIzdztvjxR4-y%7EXUCeYWJkJ-alD-kUGM7-oz9Mcd6VX9axM1yj%7EtFqtSeWFw5XBRxeq8OMGFKM%7EaYqQInElus5VR3HhUe0DS4S4OSTKSkApblo2zN9tgYF-3Q08JaYMkTGNoNzQJ1upVklbfk7QYYfzkWEsHbg__&Key-Pair-Id=K24J24Z295AEI9\n",
      "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 18.160.172.71, 18.160.172.78, 18.160.172.36, ...\n",
      "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|18.160.172.71|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 307000117 (293M) [application/zip]\n",
      "Saving to: ‘lsdir_ft_rgb_f16c12.pth’\n",
      "\n",
      "lsdir_ft_rgb_f16c12 100%[===================>] 292.78M   983KB/s    in 5m 11s  \n",
      "\n",
      "2025-04-14 14:41:21 (964 KB/s) - ‘lsdir_ft_rgb_f16c12.pth’ saved [307000117/307000117]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://huggingface.co/danjacobellis/dance/resolve/main/lsdir_ft_rgb_f16c12.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edb7d1ed-cfe7-4a60-a5ef-4e7083205b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import PIL.Image\n",
    "import io\n",
    "import numpy as np\n",
    "import datasets\n",
    "import time\n",
    "from types import SimpleNamespace\n",
    "from datasets import Dataset\n",
    "from torchvision.transforms.v2 import CenterCrop\n",
    "from torchvision.transforms.v2.functional import to_pil_image, pil_to_tensor\n",
    "from autocodec.codec import AutoCodecND, latent_to_pil, pil_to_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b06d2d79-fd36-419d-bfc8-96579af4aae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_and_evaluate(sample, quality=0.1):\n",
    "    img = sample['image']\n",
    "    x_orig = pil_to_tensor(img).to(device).unsqueeze(0).to(torch.float) / 127.5 - 1.0\n",
    "    orig_dim = x_orig.numel() \n",
    "\n",
    "    t0 = time.time()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x_orig)\n",
    "        latent = model.quantize.compand(z).round()\n",
    "    webp = latent_to_pil(latent.cpu(), n_bits=8, C=3)\n",
    "    buff = io.BytesIO()\n",
    "    webp[0].save(buff, format='WEBP', lossless=True)\n",
    "    neural_encode_time = time.time() - t0\n",
    "    \n",
    "    return {\n",
    "        'neural_encode_time': neural_encode_time,\n",
    "        'mp':orig_dim/3e6\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5324e50-c936-4374-a382-3029cb398692",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "valid_dataset = datasets.load_dataset(\"danjacobellis/LSDIR_val\", split='validation').select(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96f2bd3e-e30c-4873-bf2d-1cbcb2ca23f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.499356\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('lsdir_ft_rgb_f16c12.pth', map_location=device,weights_only=False)\n",
    "config = checkpoint['config']\n",
    "state_dict = checkpoint['state_dict']\n",
    "\n",
    "model = AutoCodecND(\n",
    "    dim=2,\n",
    "    input_channels=config.input_channels,\n",
    "    J=int(np.log2(config.F)),\n",
    "    latent_dim=config.latent_dim,\n",
    "    encoder_depth = config.encoder_depth,\n",
    "    encoder_kernel_size=config.encoder_kernel_size,\n",
    "    decoder_depth = config.decoder_depth,\n",
    "    lightweight_encode=config.lightweight_encode,\n",
    "    lightweight_decode=config.lightweight_decode,\n",
    ").to(device)\n",
    "model.load_state_dict(state_dict)\n",
    "del model.decoder_blocks\n",
    "model.eval();\n",
    "print(sum(p.numel() for p in model.parameters())/1e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "376ce266-3cdc-4cad-833d-2c309f450ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.compile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d30e515-2200-47cd-966c-f246ff51679d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f287654ef4404e0a8e492a3ff994913d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.3628, 0.5137, 0.4877, 0.4579, 0.4626, 0.4794, 0.4651, 0.5010, 0.4909,\n",
       "        0.5163])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = valid_dataset.map(lambda batch: compress_and_evaluate(batch,0.45)).with_format('torch')\n",
    "r['mp'] / r['neural_encode_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80a76554-57d2-4608-8ac1-824c4afda0af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4738)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(r['mp'] / r['neural_encode_time']).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
