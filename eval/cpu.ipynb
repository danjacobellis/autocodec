{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e441ad02-4c37-4207-8d36-c9e9e2cd4b8f",
   "metadata": {},
   "source": [
    "Music (stereo) – Stable Audio\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df1f5a65-4d9d-4c41-b7ad-80c194133af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
      "```\n",
      "pip install accelerate\n",
      "```\n",
      ".\n",
      "/home/dgj335/.local/lib/python3.11/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L: 4096; 88.73395201718911\n",
      "L: 65536; 229.36807058662532\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "from diffusers.models.autoencoders import AutoencoderOobleck\n",
    "codec = AutoencoderOobleck.from_pretrained(\n",
    "    \"stabilityai/stable-audio-open-1.0\",\n",
    "    subfolder='vae',\n",
    "    torch_dtype=torch.float\n",
    ")\n",
    "codec.eval();\n",
    "\n",
    "for L in [2**12, 2**16]:\n",
    "    encode_time = []\n",
    "    for i_trial in range(101):\n",
    "        x = torch.randn((1,2,L)).clamp(-1,1).to(torch.float)\n",
    "        t0 = time.time()\n",
    "        z = codec.encode(x).latent_dist.mode().to(torch.float16).to(\"cpu\")\n",
    "        torch.save(z,'temp.pth')\n",
    "        encode_time.append(time.time() - t0)\n",
    "    print(f'L: {L}; {L/np.median(encode_time)/1e3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a770b23-a736-4c88-9ad4-9934f5a14d61",
   "metadata": {},
   "source": [
    "---\n",
    "Music (stereo) – LiveAction\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5af2f45a-abeb-4faf-af81-2a95682cbdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L: 4096; 323.75752268958234\n",
      "L: 65536; 5012.178748842129\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import einops\n",
    "from types import SimpleNamespace\n",
    "from datasets import load_dataset, Image\n",
    "from autocodec.codec import AutoCodecND, latent_to_pil, pil_to_latent\n",
    "\n",
    "device = 'cpu'\n",
    "checkpoint = torch.load('../../hf/autocodec/musdb_stereo_f512c16.pth', map_location=\"cpu\",weights_only=False)\n",
    "config = checkpoint['config']\n",
    "state_dict = checkpoint['state_dict']\n",
    "model = AutoCodecND(\n",
    "    dim=1,\n",
    "    input_channels=config.input_channels,\n",
    "    J = int(np.log2(config.F)),\n",
    "    latent_dim=config.latent_dim,\n",
    "    encoder_depth = config.encoder_depth,\n",
    "    encoder_kernel_size = config.encoder_kernel_size,\n",
    "    decoder_depth = config.decoder_depth,\n",
    "    lightweight_encode = config.lightweight_encode,\n",
    "    lightweight_decode = config.lightweight_decode,\n",
    ").to(device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval();\n",
    "\n",
    "for L in [2**12, 2**16]:\n",
    "    encode_time = []\n",
    "    for i_trial in range(101):\n",
    "        x = torch.randn((1,2,L)).clamp(-1,1)\n",
    "        t0 = time.time()\n",
    "        z = model.quantize.compand(model.encode(x)).round().cpu()\n",
    "        latent_img = latent_to_pil(z.unsqueeze(0), n_bits=8, C=1)\n",
    "        buff = io.BytesIO()\n",
    "        latent_img[0].save(buff, format='TIFF', compression='tiff_adobe_deflate')\n",
    "        tiff_bytes = buff.getbuffer()\n",
    "        encode_time.append(time.time() - t0)\n",
    "    print(f'L: {L}; {L/np.median(encode_time)/1e3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84bbf90-10d3-4502-887e-de709ea0b1b3",
   "metadata": {},
   "source": [
    "---\n",
    "RGB Image – LiveAction F16C48\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42ceb80d-0b97-4707-a253-38366fec9467",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import time\n",
    "import torch\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "from types import SimpleNamespace\n",
    "from autocodec.codec import AutoCodecND, latent_to_pil, pil_to_latent\n",
    "\n",
    "device = \"cpu\"\n",
    "checkpoint = torch.load('../../hf/autocodec/rgb_f16c48_ft.pth', map_location=\"cpu\",weights_only=False)\n",
    "config = checkpoint['config']\n",
    "state_dict = checkpoint['state_dict']\n",
    "model = AutoCodecND(\n",
    "    dim=2,\n",
    "    input_channels=config.input_channels,\n",
    "    J = int(np.log2(config.F)),\n",
    "    latent_dim=config.latent_dim,\n",
    "    encoder_depth = config.encoder_depth,\n",
    "    encoder_kernel_size = config.encoder_kernel_size,\n",
    "    decoder_depth = config.decoder_depth,\n",
    "    lightweight_encode = config.lightweight_encode,\n",
    "    lightweight_decode = config.lightweight_decode,\n",
    ").to(device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval();\n",
    "\n",
    "for S in [, 2**16]:\n",
    "    encode_time = []\n",
    "    for i_trial in range(5):\n",
    "        x = torch.randn((1,2,L)).clamp(-1,1)\n",
    "        t0 = time.time()\n",
    "        z = model.quantize.compand(model.encode(x)).round().cpu()\n",
    "        latent_img = latent_to_pil(z.unsqueeze(0), n_bits=8, C=1)\n",
    "        buff = io.BytesIO()\n",
    "        latent_img[0].save(buff, format='TIFF', compression='tiff_adobe_deflate')\n",
    "        tiff_bytes = buff.getbuffer()\n",
    "        encode_time = time.time() - t0\n",
    "    print(f'L: {L}; {L/np.median(encode_time)/1e3}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620b5c0d-8e9a-4754-b012-53ddd125d0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
