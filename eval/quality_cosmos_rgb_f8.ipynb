{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fc4d032-ac60-4670-9f79-f48f9a6ee4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import time\n",
    "import torch\n",
    "import datasets\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from types import SimpleNamespace\n",
    "from piq import LPIPS, DISTS, SSIMLoss\n",
    "from huggingface_hub import snapshot_download\n",
    "from cosmos_tokenizer.image_lib import ImageTokenizer\n",
    "from torchvision.transforms.v2 import Pad, CenterCrop\n",
    "from torchvision.transforms.v2.functional import to_pil_image, pil_to_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32bae16e-d171-4dbb-ba37-5672dc433186",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dgj335/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/dgj335/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b253d2ba47c641db9cb2f6c4ff3fca49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a98778b59e84f1f8e484910914d7e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4975f288fcb94902a31ec1970564e989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 7 files:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "lpips_loss = LPIPS().to(device)\n",
    "dists_loss = DISTS().to(device)\n",
    "ssim_loss = SSIMLoss().to(device)\n",
    "kodak = datasets.load_dataset(\"danjacobellis/kodak\", split='validation')\n",
    "lsdir = datasets.load_dataset(\"danjacobellis/LSDIR_val\", split='validation')\n",
    "inet = datasets.load_dataset(\"timm/imagenet-1k-wds\",split='validation')\n",
    "model_path = snapshot_download(repo_id='nvidia/Cosmos-Tokenizer-DI8x8')\n",
    "encoder = ImageTokenizer(checkpoint_enc=f'{model_path}/encoder.jit').to(device)\n",
    "decoder = ImageTokenizer(checkpoint_dec=f'{model_path}/decoder.jit').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f643d1d8-a23b-49bd-8a2d-cc74719cf545",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_quality_h1024(sample):\n",
    "    img = sample['jpg'].convert(\"RGB\")\n",
    "    aspect = img.width/img.height\n",
    "    img = img.resize((int(16*(1024*aspect//16)),1024),resample=PIL.Image.Resampling.LANCZOS)\n",
    "    x_orig = pil_to_tensor(img).to(device).unsqueeze(0).to(torch.float) / 127.5 - 1.0\n",
    "    orig_dim = x_orig.numel() \n",
    "\n",
    "    t0 = time.time()\n",
    "    with torch.no_grad():\n",
    "        z, _ = encoder.encode(x_orig)\n",
    "    encode_time = time.time() - t0\n",
    "    size_bytes = 2*z.numel()\n",
    "    t0 = time.time()\n",
    "    with torch.no_grad():\n",
    "        z, _ = encoder.encode(x_orig)\n",
    "        x_hat = decoder.decode(z).to(torch.float).clamp(-1,1)\n",
    "    decode_time = time.time() - t0\n",
    "\n",
    "    x_orig_01 = x_orig / 2 + 0.5\n",
    "    x_hat_01 = x_hat / 2 + 0.5\n",
    "\n",
    "    pixels = img.width * img.height\n",
    "    bpp = 8 * size_bytes / pixels\n",
    "    mse = torch.nn.functional.mse_loss(x_orig_01[0], x_hat_01[0])\n",
    "    PSNR = -10 * mse.log10().item()\n",
    "    LPIPS_dB = -10 * np.log10(lpips_loss(x_orig_01.to(\"cuda\"), x_hat_01.to(\"cuda\")).item())\n",
    "    DISTS_dB = -10 * np.log10(dists_loss(x_orig_01.to(\"cuda\"), x_hat_01.to(\"cuda\")).item())\n",
    "    SSIM = 1 - ssim_loss(x_orig_01.to(\"cuda\"), x_hat_01.to(\"cuda\")).item()\n",
    "\n",
    "    return {\n",
    "        'encode_time': encode_time,\n",
    "        'decode_time': decode_time,\n",
    "        'bpp': bpp,\n",
    "        'PSNR': PSNR,\n",
    "        'LPIPS_dB': LPIPS_dB,\n",
    "        'DISTS_dB': DISTS_dB,\n",
    "        'SSIM': SSIM,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f8325c-2b49-47a5-aeaa-635baf18d489",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function evaluate_quality_h1024 at 0x786dac628430> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c652ca7213ab4addb46a8baf923c3540",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_dataset = inet.map(evaluate_quality_h1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5ba4c01d-d8fe-4d99-9f99-080619403441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\n",
      "---\n",
      "encode_time: 0.05055922746658325\n",
      "decode_time: 0.10153760433197022\n",
      "bpp: 0.0625\n",
      "PSNR: 24.753208494186403\n",
      "LPIPS_dB: 5.816998623644801\n",
      "DISTS_dB: 11.682074767345494\n",
      "SSIM: 0.8084122937917709\n"
     ]
    }
   ],
   "source": [
    "print(\"mean\\n---\")\n",
    "for metric in [\n",
    "    'bpp',\n",
    "    'PSNR',\n",
    "    'LPIPS_dB',\n",
    "    'DISTS_dB',\n",
    "    'SSIM',\n",
    "]:\n",
    "    μ = np.mean(results_dataset[metric])\n",
    "    print(f\"{metric}: {μ}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
