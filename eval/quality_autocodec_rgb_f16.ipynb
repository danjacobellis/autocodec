{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4ceb37-7481-4fbb-bf65-f55268af45f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://huggingface.co/danjacobellis/dance/resolve/main/LF_rgb_f16c12_v1.9_finetune3.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb7d1ed-cfe7-4a60-a5ef-4e7083205b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import time\n",
    "import torch\n",
    "import datasets\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from types import SimpleNamespace\n",
    "from piq import LPIPS, DISTS, SSIMLoss\n",
    "from autocodec.codec import AutoCodecND, latent_to_pil, pil_to_latent\n",
    "from torchvision.transforms.v2 import Pad, CenterCrop, PILToTensor\n",
    "from torchvision.transforms.v2 import CenterCrop, PILToTensor, ToPILImage, Pad, CenterCrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5324e50-c936-4374-a382-3029cb398692",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "lpips_loss = LPIPS().to(device)\n",
    "dists_loss = DISTS().to(device)\n",
    "ssim_loss = SSIMLoss().to(device)\n",
    "kodak = datasets.load_dataset(\"danjacobellis/kodak\", split='validation')\n",
    "lsdir = datasets.load_dataset(\"danjacobellis/LSDIR_val\", split='validation')\n",
    "inet = datasets.load_dataset(\"timm/imagenet-1k-wds\",split='validation')\n",
    "checkpoint = torch.load('LF_rgb_f16c12_v1.9_finetune3.pth', map_location=device,weights_only=False)\n",
    "config = checkpoint['config']\n",
    "state_dict = checkpoint['state_dict']\n",
    "\n",
    "model = AutoCodecND(\n",
    "    dim=2,\n",
    "    input_channels=config.input_channels,\n",
    "    J=int(config.F**0.5),\n",
    "    latent_dim=config.latent_dim,\n",
    "    encoder_depth = config.encoder_depth,\n",
    "    encoder_kernel_size = config.encoder_kernel_size,\n",
    "    decoder_depth = config.decoder_depth,\n",
    "    lightweight_encode=config.lightweight_encode,\n",
    "    lightweight_decode=config.lightweight_decode,\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06d2d79-fd36-419d-bfc8-96579af4aae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_quality_h1024(sample):\n",
    "    img = sample['jpg'].convert(\"RGB\")\n",
    "    aspect = img.width/img.height\n",
    "    img = img.resize((int(16*(1024*aspect//16)),1024),resample=PIL.Image.Resampling.LANCZOS)\n",
    "    x_orig = PILToTensor()(img).to(device).unsqueeze(0).to(torch.float) / 127.5 - 1.0\n",
    "    orig_dim = x_orig.numel() \n",
    "\n",
    "    t0 = time.time()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x_orig)\n",
    "        latent = model.quantize.compand(z).round()\n",
    "    webp = latent_to_pil(latent.cpu(), n_bits=8, C=3)\n",
    "    buff = io.BytesIO()\n",
    "    webp[0].save(buff, format='WEBP', lossless=True)\n",
    "    encode_time = time.time() - t0\n",
    "    size_bytes = len(buff.getbuffer())\n",
    "    t0 = time.time()\n",
    "    latent_decoded = pil_to_latent(webp, N=config.latent_dim, n_bits=8, C=3).to(device)\n",
    "    with torch.no_grad():\n",
    "        x_hat = model.decode(latent_decoded).clamp(-1,1)\n",
    "    decode_time = time.time() - t0\n",
    "\n",
    "    x_orig_01 = x_orig / 2 + 0.5\n",
    "    x_hat_01 = x_hat / 2 + 0.5\n",
    "\n",
    "    pixels = img.width * img.height\n",
    "    bpp = 8 * size_bytes / pixels\n",
    "    mse = torch.nn.functional.mse_loss(x_orig_01[0], x_hat_01[0])\n",
    "    PSNR = -10 * mse.log10().item()\n",
    "    LPIPS_dB = -10 * np.log10(lpips_loss(x_orig_01.to(\"cuda\"), x_hat_01.to(\"cuda\")).item())\n",
    "    DISTS_dB = -10 * np.log10(dists_loss(x_orig_01.to(\"cuda\"), x_hat_01.to(\"cuda\")).item())\n",
    "    SSIM = 1 - ssim_loss(x_orig_01.to(\"cuda\"), x_hat_01.to(\"cuda\")).item()\n",
    "\n",
    "    return {\n",
    "        'bpp': bpp,\n",
    "        'PSNR': PSNR,\n",
    "        'LPIPS_dB': LPIPS_dB,\n",
    "        'DISTS_dB': DISTS_dB,\n",
    "        'SSIM': SSIM,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d30e515-2200-47cd-966c-f246ff51679d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dataset = inet.map(evaluate_quality_h1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1a572d-9b99-41c1-add1-ab644e3738c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"mean\\n---\")\n",
    "for metric in [\n",
    "    'bpp',\n",
    "    'PSNR',\n",
    "    'LPIPS_dB',\n",
    "    'DISTS_dB',\n",
    "    'SSIM',\n",
    "]:\n",
    "    μ = np.mean(results_dataset[metric])\n",
    "    print(f\"{metric}: {μ}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
