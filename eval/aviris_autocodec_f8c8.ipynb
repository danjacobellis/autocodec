{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89b4dc22-bdb4-4327-8964-869e0631a703",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import datasets\n",
    "import einops\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from types import SimpleNamespace\n",
    "from autocodec.codec import AutoCodecND, latent_to_pil, pil_to_latent\n",
    "from torchvision.transforms.v2.functional import to_pil_image, pil_to_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57c7672d-c57e-42b5-9c96-fff6fa841f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1948ed769aba48e2a6fd4808805ee9d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "830b99bf06624ecfb1f2e37916c76927",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/66 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "538c2a04080642409ba11fd6fad59663",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/48 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "aviris = datasets.load_dataset(\"danjacobellis/aviris_1k_val\", split=\"validation\")\n",
    "\n",
    "checkpoint = torch.load('../../hf/autocodec/hyper_f8c8.pth', map_location=\"cpu\", weights_only=False)\n",
    "config = checkpoint['config']\n",
    "state_dict = checkpoint['state_dict']\n",
    "\n",
    "model = AutoCodecND(\n",
    "    dim=3,\n",
    "    input_channels=config.input_channels,\n",
    "    J=int(np.log2(config.F)),\n",
    "    latent_dim=config.latent_dim,\n",
    "    encoder_depth=config.encoder_depth,\n",
    "    encoder_kernel_size=config.encoder_kernel_size,\n",
    "    decoder_depth=config.decoder_depth,\n",
    "    lightweight_encode=config.lightweight_encode,\n",
    "    lightweight_decode=config.lightweight_decode,\n",
    ").to(device).to(torch.bfloat16)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaf665d4-12d9-461c-9ea2-e3ce652004ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad3d(x, p, extra, small_dim_mode):\n",
    "    b, c, f, h, w = x.shape\n",
    "    extra_f, extra_h, extra_w = extra  # Unpack the extra tuple for each dimension\n",
    "    \n",
    "    for dim, size, extra_pad in zip(['f', 'h', 'w'], [f, h, w], [extra_f, extra_h, extra_w]):\n",
    "        if small_dim_mode and size < p:\n",
    "            pad1 = extra_pad\n",
    "            pad2 = extra_pad\n",
    "        else:\n",
    "            t = math.ceil(size / p) * p\n",
    "            pad_total = t - size\n",
    "            pad1 = pad_total // 2\n",
    "            pad2 = pad_total - pad1\n",
    "            pad1 += extra_pad\n",
    "            pad2 += extra_pad\n",
    "        if dim == 'f':\n",
    "            fp1, fp2 = pad1, pad2\n",
    "        elif dim == 'h':\n",
    "            hp1, hp2 = pad1, pad2\n",
    "        elif dim == 'w':\n",
    "            wp1, wp2 = pad1, pad2\n",
    "            \n",
    "    return torch.nn.functional.pad(\n",
    "        x,\n",
    "        pad=(wp1, wp2, hp1, hp2, fp1, fp2),\n",
    "        mode=\"reflect\"\n",
    "    )\n",
    "\n",
    "def center_crop_3d(x, f, h, w):\n",
    "    assert x.ndim == 5\n",
    "    _, _, F, H, W = x.shape\n",
    "    front = (F - f) // 2\n",
    "    back  = front + f\n",
    "    top   = (H - h) // 2\n",
    "    bottom = top + h\n",
    "    left  = (W - w) // 2\n",
    "    right = left + w\n",
    "    return x[:, :, front:back, top:bottom, left:right]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c7a630b-dd90-4efc-9846-9f0a1033dd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = aviris[0]\n",
    "\n",
    "img = sample['image']\n",
    "bands = []\n",
    "for i in range(img.n_frames):\n",
    "    img.seek(i)\n",
    "    bands.append(np.array(img, dtype=np.int16))\n",
    "x_orig = torch.from_numpy(np.stack(bands)).to(device).to(torch.bfloat16).unsqueeze(0).unsqueeze(0) / 32768.0\n",
    "x = pad3d(x_orig, config.F, extra=(0,0,0), small_dim_mode=False)\n",
    "\n",
    "t0 = time.time()\n",
    "with torch.no_grad():\n",
    "    z = model.quantize.compand(model.encode(x)).round()\n",
    "z = einops.rearrange(z, 'b c f h w -> (c f) b h w')\n",
    "img_list = latent_to_pil(z.cpu(), n_bits=8, C=1)\n",
    "\n",
    "buff = []\n",
    "for img in img_list:\n",
    "    buff.append(io.BytesIO())\n",
    "    img.save(buff[-1], format= \"TIFF\", compression='tiff_adobe_deflate')\n",
    "encode_time = time.time() - t0\n",
    "\n",
    "size_bytes = sum(len(b.getbuffer()) for b in buff)\n",
    "cr = 2*x.numel() / size_bytes\n",
    "\n",
    "t0 = time.time()\n",
    "z = pil_to_latent([PIL.Image.open(b) for b in buff], N=1, n_bits=8, C=1)\n",
    "z = einops.rearrange(z, '(c f) b h w -> b c f h w', c = config.latent_dim).to(device).to(torch.bfloat16)\n",
    "with torch.no_grad():\n",
    "    xhat = model.decode(z).clamp(-1,1)\n",
    "\n",
    "decode_time = time.time() - t0\n",
    "\n",
    "xhat = center_crop_3d(x=xhat, f=x_orig.shape[2], h=x_orig.shape[3], w=x_orig.shape[4])\n",
    "mse = torch.nn.functional.mse_loss(x_orig.to(torch.float),xhat.to(torch.float))\n",
    "psnr = -10*mse.log10().item() + 6.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8677d531-b5cc-409d-ab08-498aa0fc354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_quality(sample):   \n",
    "    img = sample['image']\n",
    "    bands = []\n",
    "    for i in range(img.n_frames):\n",
    "        img.seek(i)\n",
    "        bands.append(np.array(img, dtype=np.int16))\n",
    "    x_orig = torch.from_numpy(np.stack(bands)).to(device).to(torch.bfloat16).unsqueeze(0).unsqueeze(0) / 32768.0\n",
    "    x = pad3d(x_orig, config.F, extra=(0,0,0), small_dim_mode=False)\n",
    "    \n",
    "    t0 = time.time()\n",
    "    with torch.no_grad():\n",
    "        z = model.quantize.compand(model.encode(x)).round()\n",
    "    z = einops.rearrange(z, 'b c f h w -> (c f) b h w')\n",
    "    img_list = latent_to_pil(z.cpu(), n_bits=8, C=1)\n",
    "    \n",
    "    buff = []\n",
    "    for img in img_list:\n",
    "        buff.append(io.BytesIO())\n",
    "        img.save(buff[-1], format= \"TIFF\", compression='tiff_adobe_deflate')\n",
    "    encode_time = time.time() - t0\n",
    "    \n",
    "    size_bytes = sum(len(b.getbuffer()) for b in buff)\n",
    "    cr = 2*x.numel() / size_bytes\n",
    "    \n",
    "    t0 = time.time()\n",
    "    z = pil_to_latent([PIL.Image.open(b) for b in buff], N=1, n_bits=8, C=1)\n",
    "    z = einops.rearrange(z, '(c f) b h w -> b c f h w', c = config.latent_dim).to(device).to(torch.bfloat16)\n",
    "    with torch.no_grad():\n",
    "        xhat = model.decode(z).clamp(-1,1)\n",
    "    \n",
    "    decode_time = time.time() - t0\n",
    "    \n",
    "    xhat = center_crop_3d(x=xhat, f=x_orig.shape[2], h=x_orig.shape[3], w=x_orig.shape[4])\n",
    "    mse = torch.nn.functional.mse_loss(x_orig.to(torch.float),xhat.to(torch.float))\n",
    "    psnr = -10*mse.log10().item() + 6.02\n",
    "\n",
    "    return {\n",
    "        \"voxels\": x_orig.numel(),\n",
    "        \"encode_time\": encode_time,\n",
    "        \"decode_time\": decode_time,\n",
    "        \"cr\": cr,\n",
    "        \"psnr\": psnr,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "235c4f55-0ba5-411a-add1-eeb92a7fb6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    'voxels',\n",
    "    'encode_time',\n",
    "    'decode_time',\n",
    "    'cr',\n",
    "    'psnr',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fb4cfb7-ace4-447a-87f7-f18b302e77ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dataset = aviris.map(evaluate_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4e75f8a-05cb-4f13-8cf9-712dadbbb824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\n",
      "---\n",
      "voxels: 87734420.76595744\n",
      "encode_time: 0.14616816094581117\n",
      "decode_time: 0.0333839883195593\n",
      "cr: 574.5738471332235\n",
      "psnr: 18.52037821049386\n",
      "600.1471162177203 MVox/sec\n",
      "2680.8554334029 MVox/sec\n"
     ]
    }
   ],
   "source": [
    "print(\"mean\\n---\")\n",
    "for metric in metrics:\n",
    "    μ = np.mean(results_dataset[metric])\n",
    "    print(f\"{metric}: {μ}\")\n",
    "print(f\"{np.mean(np.array(results_dataset['voxels'])/1e6/np.array(results_dataset['encode_time']))} MVox/sec\")\n",
    "print(f\"{np.mean(np.array(results_dataset['voxels'])/1e6/np.array(results_dataset['decode_time']))} MVox/sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "988a27b6-60a1-4b9d-bfd7-cee0e2573495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\n",
      "---\n",
      "voxels: 87734420.76595744\n",
      "encode_time: 0.14616816094581117\n",
      "decode_time: 0.0333839883195593\n",
      "cr: 574.5738471332235\n",
      "psnr: 18.52037821049386\n",
      "600.1471162177203 MVox/sec\n",
      "2680.8554334029 MVox/sec\n"
     ]
    }
   ],
   "source": [
    "print(\"mean\\n---\")\n",
    "for metric in metrics:\n",
    "    μ = np.mean(results_dataset[metric])\n",
    "    print(f\"{metric}: {μ}\")\n",
    "print(f\"{np.mean(np.array(results_dataset['voxels'])/1e6/np.array(results_dataset['encode_time']))} MVox/sec\")\n",
    "print(f\"{np.mean(np.array(results_dataset['voxels'])/1e6/np.array(results_dataset['decode_time']))} MVox/sec\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
