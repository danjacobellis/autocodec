{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d7db02c-516f-4ddd-ba4a-31b7dcc18526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import PIL\n",
    "import torchaudio\n",
    "import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "import einops\n",
    "from IPython.display import Audio\n",
    "from types import SimpleNamespace\n",
    "from torchvision.transforms.v2 import CenterCrop\n",
    "from transformers import EncodecModel, AutoProcessor\n",
    "from IPython.display import Audio as play\n",
    "from spauq.core.metrics import spauq_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12230ef2-5459-483f-967c-5cb734c5774c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(audio, p=2**16):\n",
    "    B, C, L = audio.shape\n",
    "    padding_size = (p - (L % p)) % p\n",
    "    if padding_size > 0:\n",
    "        left_pad = padding_size // 2\n",
    "        right_pad = padding_size - left_pad\n",
    "        audio = torch.nn.functional.pad(audio, (left_pad, right_pad), mode='constant', value=0)\n",
    "    return audio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eea68b9d-1e5a-432f-af4a-8ad4447fcf3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91f7022c47ed444fa0915107357c0945",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2cb4225fc094ed88db0dc5650c779d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(\"danjacobellis/aria_ea_audio_preprocessed\").with_format(\"numpy\",dtype='float16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37a32ba4-7389-4f20-9887-ed52c042dc56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "encodec_model = EncodecModel.from_pretrained(\"facebook/encodec_48khz\").to(device)\n",
    "encodec_processor = AutoProcessor.from_pretrained(\"facebook/encodec_48khz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b058c4f7-5502-4d3d-81b6-c318c3e8e480",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_quality(sample):\n",
    "    \n",
    "    x_orig = torch.tensor(sample['audio']).permute(1,0).to(torch.float)\n",
    "    L = x_orig.shape[-1]\n",
    "    \n",
    "    encode_time = 0\n",
    "    decode_time = 0\n",
    "    compressed_size_bits = 0\n",
    "    \n",
    "    x = []\n",
    "    xhat = []\n",
    "    for c in range(0,7,2):\n",
    "        channels = x_orig[c:c+2]\n",
    "        if channels.shape[0] != 2:\n",
    "            channels = torch.cat([channels,channels])\n",
    "        inputs = encodec_processor(raw_audio=channels, sampling_rate=48000, return_tensors='pt')\n",
    "        xi = inputs.input_values.to(device)\n",
    "        padding_mask = inputs.padding_mask.to(device)\n",
    "        \n",
    "        t0 = time.time()\n",
    "        with torch.no_grad():\n",
    "            encoder_outputs = encodec_model.encode(xi, padding_mask)\n",
    "        buff = io.BytesIO()\n",
    "        torch.save(codes,buff)\n",
    "        encode_time += time.time() - t0\n",
    "    \n",
    "        codes = encoder_outputs.audio_codes\n",
    "        scales = encoder_outputs.audio_scales\n",
    "        compressed_size_bits += 10*codes.numel() + 16*len(scales)\n",
    "            \n",
    "        t0 = time.time()\n",
    "        with torch.no_grad():\n",
    "            xhati = encodec_model.decode(codes, scales, padding_mask)[0]\n",
    "        decode_time += time.time() - t0\n",
    "    \n",
    "        x.append(xi)\n",
    "        xhat.append(xhati)\n",
    "    \n",
    "    x = torch.cat(x,dim=1)[0,:7,:L]\n",
    "    xhat = torch.cat(xhat,dim=1)[0,:7,:L].clamp(-1,1)\n",
    "    assert x.cpu().equal(x_orig)\n",
    "    \n",
    "    cr = 16*x.numel() / compressed_size_bits\n",
    "    \n",
    "    mse = torch.nn.functional.mse_loss(x,xhat)\n",
    "    psnr = -10*mse.log10().item() + 6.02\n",
    "    \n",
    "    SDR = spauq_eval(x.cpu(),xhat.cpu(),fs=48000)\n",
    "    ssdr = SDR['SSR']\n",
    "    srdr = SDR['SRR']\n",
    "\n",
    "    return {\n",
    "        'samples': x.numel(),\n",
    "        'cr': cr,\n",
    "        'encode_time': encode_time,\n",
    "        'decode_time': decode_time,\n",
    "        'psnr': psnr,\n",
    "        'ssdr': ssdr,\n",
    "        'srdr': srdr,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73e36552-f567-4118-a241-44efb9f65061",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [\n",
    "    'samples',\n",
    "    'cr',\n",
    "    'encode_time',\n",
    "    'decode_time',\n",
    "    'psnr',\n",
    "    'ssdr',\n",
    "    'srdr',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d62f88b6-6680-49d2-bfbd-65e876ed20fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b1b5d7453814184af57c44414ef8e2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1215 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dgj335/.local/lib/python3.11/site-packages/spauq/core/preprocessing.py:325: UserWarning: No forgive_mode specified, defaulting to `none`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "gpu_results = dataset['validation'].select(range.map(evaluate_quality).with_format(\"torch\",dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa16d6e3-5d46-4a41-a2c5-8a1150e19534",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\n",
      "---\n",
      "samples: 2100000.0\n",
      "cr: 1013.5135498046875\n",
      "encode_time: 0.00596621772274375\n",
      "decode_time: 0.007144085131585598\n",
      "psnr: 33.12417984008789\n",
      "ssdr: 9.029350280761719\n",
      "srdr: 1.9624067544937134\n",
      "363.17364501953125 MS/sec\n",
      "305.7591552734375 MS/sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3814445/4291437718.py:5: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  print(f\"{np.mean(np.array(gpu_results['samples'])/1e6/np.array(gpu_results['encode_time']))} MS/sec\")\n",
      "/tmp/ipykernel_3814445/4291437718.py:6: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments. To learn more, see the migration guide https://numpy.org/devdocs/numpy_2_0_migration_guide.html#adapting-to-changes-in-the-copy-keyword\n",
      "  print(f\"{np.mean(np.array(gpu_results['samples'])/1e6/np.array(gpu_results['decode_time']))} MS/sec\")\n"
     ]
    }
   ],
   "source": [
    "print(\"mean\\n---\")\n",
    "for metric in metrics:\n",
    "    μ = gpu_results[metric].mean()\n",
    "    print(f\"{metric}: {μ}\")\n",
    "print(f\"{np.mean(np.array(gpu_results['samples'])/1e6/np.array(gpu_results['encode_time']))} MS/sec\")\n",
    "print(f\"{np.mean(np.array(gpu_results['samples'])/1e6/np.array(gpu_results['decode_time']))} MS/sec\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
