{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5911e753-ad87-4d09-8156-39004959f715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=MIG-cbafb023-40ef-594e-9092-fb0e3c44baa2\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=MIG-cbafb023-40ef-594e-9092-fb0e3c44baa2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edb7d1ed-cfe7-4a60-a5ef-4e7083205b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import PIL.Image\n",
    "import io\n",
    "import numpy as np\n",
    "import datasets\n",
    "from torchvision.transforms.v2 import Pad, CenterCrop\n",
    "from torchvision.transforms.v2.functional import pil_to_tensor, to_pil_image\n",
    "from types import SimpleNamespace\n",
    "from autocodec.codec import AutoCodecND, latent_to_pil, pil_to_latent\n",
    "from piq import LPIPS, DISTS, SSIMLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad55c948-ab26-4834-8213-56ce0f3c6d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dgj335/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/dgj335/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\"\n",
    "lpips_loss = LPIPS().to(device)\n",
    "dists_loss = DISTS().to(device)\n",
    "ssim_loss = SSIMLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5324e50-c936-4374-a382-3029cb398692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "459316954706498a8cf4d9b1d18108d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50ecb87785d949578d398cf17e15c202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inet = datasets.load_dataset(\"timm/imagenet-1k-wds\",split='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96f2bd3e-e30c-4873-bf2d-1cbcb2ca23f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('../../hf/dance/rgb_f8c12.pth', map_location=device,weights_only=False)\n",
    "config = checkpoint['config']\n",
    "state_dict = checkpoint['state_dict']\n",
    "\n",
    "model = AutoCodecND(\n",
    "    dim=2,\n",
    "    input_channels=config.input_channels,\n",
    "    J = int(np.log2(config.F)),\n",
    "    latent_dim=config.latent_dim,\n",
    "    encoder_depth = config.encoder_depth,\n",
    "    encoder_kernel_size = config.encoder_kernel_size,\n",
    "    decoder_depth = config.decoder_depth,\n",
    "    lightweight_encode = config.lightweight_encode,\n",
    "    lightweight_decode = config.lightweight_decode,\n",
    ").to(device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b06d2d79-fd36-419d-bfc8-96579af4aae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress_and_evaluate(sample):\n",
    "    img = sample['jpg'].convert(\"RGB\")\n",
    "    aspect = img.width/img.height\n",
    "    img = img.resize((int(16*(1024*aspect//16)),1024),resample=PIL.Image.Resampling.LANCZOS)\n",
    "    x_orig = pil_to_tensor(img).to(device).unsqueeze(0).to(torch.float) / 127.5 - 1.0\n",
    "    orig_dim = x_orig.numel() \n",
    "\n",
    "    t0 = time.time()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x_orig)\n",
    "        latent = model.quantize.compand(z).round()\n",
    "    webp = latent_to_pil(latent.cpu(), n_bits=8, C=3)\n",
    "    buff = io.BytesIO()\n",
    "    webp[0].save(buff, format='WEBP', lossless=True)\n",
    "    encode_time = time.time() - t0\n",
    "    size_bytes = len(buff.getbuffer())\n",
    "    t0 = time.time()\n",
    "    latent_decoded = pil_to_latent(webp, N=config.latent_dim, n_bits=8, C=3).to(device)\n",
    "    with torch.no_grad():\n",
    "        x_hat = model.decode(latent_decoded).clamp(-1,1)\n",
    "    decode_time = time.time() - t0\n",
    "\n",
    "    x_orig_01 = x_orig / 2 + 0.5\n",
    "    x_hat_01 = x_hat / 2 + 0.5\n",
    "\n",
    "    pixels = img.width * img.height\n",
    "    bpp = 8 * size_bytes / pixels\n",
    "    mse = torch.nn.functional.mse_loss(x_orig_01[0], x_hat_01[0])\n",
    "    PSNR = -10 * mse.log10().item()\n",
    "    LPIPS_dB = -10 * np.log10(lpips_loss(x_orig_01.to(device), x_hat_01.to(device)).item())\n",
    "    DISTS_dB = -10 * np.log10(dists_loss(x_orig_01.to(device), x_hat_01.to(device)).item())\n",
    "    SSIM = 1 - ssim_loss(x_orig_01.to(device), x_hat_01.to(device)).item()\n",
    "\n",
    "    return {\n",
    "        'pixels': pixels,\n",
    "        'bpp': bpp,\n",
    "        'PSNR': PSNR,\n",
    "        'LPIPS_dB': LPIPS_dB,\n",
    "        'DISTS_dB': DISTS_dB,\n",
    "        'SSIM': SSIM,\n",
    "        'encode_time': encode_time,\n",
    "        'decode_time': decode_time,\n",
    "    }\n",
    "\n",
    "metrics = [\n",
    "    'pixels',\n",
    "    'bpp',\n",
    "    'PSNR',\n",
    "    'LPIPS_dB',\n",
    "    'DISTS_dB',\n",
    "    'SSIM',\n",
    "    'encode_time',\n",
    "    'decode_time',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b4d479-1d3c-4c55-aba0-978e86f7d786",
   "metadata": {},
   "source": [
    "f16c12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bd0d643-d4e4-4093-94e5-7e325506642d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e72b981da4b4cff9c4a7d3cd19f3580",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\n",
      "---\n",
      "pixels: 1227161.6\n",
      "bpp: 0.14648919167678695\n",
      "PSNR: 31.021453261375427\n",
      "LPIPS_dB: 5.973899995484275\n",
      "DISTS_dB: 11.845230856928634\n",
      "SSIM: 0.9448394024372101\n",
      "encode_time: 0.015861053466796875\n",
      "decode_time: 0.008933014869689941\n",
      "80.04927627255795 MP/sec\n"
     ]
    }
   ],
   "source": [
    "results_dataset = inet.select(range(100)).map(compress_and_evaluate)\n",
    "\n",
    "print(\"mean\\n---\")\n",
    "for metric in metrics:\n",
    "    μ = np.mean(results_dataset[metric])\n",
    "    print(f\"{metric}: {μ}\")\n",
    "print(f\"{np.mean(np.array(results_dataset['pixels'])/1e6/np.array(results_dataset['encode_time']))} MP/sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3046cb-3dca-41b6-83f9-8904db8a3b39",
   "metadata": {},
   "source": [
    "f8c12 lsdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fd81ff40-a3bf-4e56-bbb2-6134e22e305f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4a80848c5ac4de7a26439180c3bcf66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\n",
      "---\n",
      "pixels: 1227161.6\n",
      "bpp: 0.5912512305003398\n",
      "PSNR: 36.13458340167999\n",
      "LPIPS_dB: 8.652118808188026\n",
      "DISTS_dB: 16.805981208572174\n",
      "SSIM: 0.9812395268678665\n",
      "encode_time: 0.05376312255859375\n",
      "decode_time: 0.007639296054840088\n",
      "26.120858451126278 MP/sec\n"
     ]
    }
   ],
   "source": [
    "results_dataset = inet.select(range(100)).map(compress_and_evaluate)\n",
    "\n",
    "print(\"mean\\n---\")\n",
    "for metric in metrics:\n",
    "    μ = np.mean(results_dataset[metric])\n",
    "    print(f\"{metric}: {μ}\")\n",
    "print(f\"{np.mean(np.array(results_dataset['pixels'])/1e6/np.array(results_dataset['encode_time']))} MP/sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296bbcbb-2a5e-4ba5-8164-766f2ba6600f",
   "metadata": {},
   "source": [
    "f8c12 lsdir+inet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "755fccc5-e859-4d3b-b8b1-80a8faba94fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6272569fafb54b6ebed4d6adb118b22d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\n",
      "---\n",
      "pixels: 1227161.6\n",
      "bpp: 0.6510875973063395\n",
      "PSNR: 38.71788156032562\n",
      "LPIPS_dB: 10.73722696227855\n",
      "DISTS_dB: 19.70042709393359\n",
      "SSIM: 0.988203484416008\n",
      "encode_time: 0.057140915393829345\n",
      "decode_time: 0.00765207052230835\n",
      "24.919460404154268 MP/sec\n"
     ]
    }
   ],
   "source": [
    "results_dataset = inet.select(range(100)).map(compress_and_evaluate)\n",
    "\n",
    "print(\"mean\\n---\")\n",
    "for metric in metrics:\n",
    "    μ = np.mean(results_dataset[metric])\n",
    "    print(f\"{metric}: {μ}\")\n",
    "print(f\"{np.mean(np.array(results_dataset['pixels'])/1e6/np.array(results_dataset['encode_time']))} MP/sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ebef83-9cca-42c5-b63e-4a603c8b9555",
   "metadata": {},
   "source": [
    "f8c12 lsdir+inet+lsdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50f49b6f-38ed-4be3-97dc-bbea1a755158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af7b5f3996864a429cee80fdfff5d03a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean\n",
      "---\n",
      "pixels: 1227161.6\n",
      "bpp: 0.6391400756471314\n",
      "PSNR: 37.93727173805237\n",
      "LPIPS_dB: 9.995588076564129\n",
      "DISTS_dB: 19.153368748923363\n",
      "SSIM: 0.9857030594348908\n",
      "encode_time: 0.0602103853225708\n",
      "decode_time: 0.010009536743164063\n",
      "23.517455320890708 MP/sec\n"
     ]
    }
   ],
   "source": [
    "results_dataset = inet.select(range(100)).map(compress_and_evaluate)\n",
    "\n",
    "print(\"mean\\n---\")\n",
    "for metric in metrics:\n",
    "    μ = np.mean(results_dataset[metric])\n",
    "    print(f\"{metric}: {μ}\")\n",
    "print(f\"{np.mean(np.array(results_dataset['pixels'])/1e6/np.array(results_dataset['encode_time']))} MP/sec\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
