{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b138243-5dd9-4ac0-8ea1-5461bcb85e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=MIG-768d9c1d-110f-52e2-b0a2-3252f78280f8\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=MIG-768d9c1d-110f-52e2-b0a2-3252f78280f8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31802a5a-cddf-4ebd-9d87-2aca01836585",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import PIL.Image\n",
    "import einops\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import datasets\n",
    "import math\n",
    "import random\n",
    "from timm.optim import Mars\n",
    "from types import SimpleNamespace\n",
    "from IPython.display import HTML\n",
    "from types import SimpleNamespace\n",
    "from fastprogress import progress_bar, master_bar\n",
    "from torchvision.transforms.v2 import CenterCrop, RandomCrop\n",
    "from torchvision.transforms.v2.functional import pil_to_tensor, to_pil_image\n",
    "from decord import VideoReader\n",
    "from autocodec.codec import AutoCodecND, latent_to_pil, pil_to_latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "550eece5-fccd-4fba-ba81-f81f73a3fd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "dataset = datasets.load_dataset(\"danjacobellis/davis\").cast_column('video',datasets.Video()).with_format(\"torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "212dc070-e81c-46ae-a394-b476d4010a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('../../hf/dance/video_f8c48.pth', map_location=\"cpu\",weights_only=False)\n",
    "config = checkpoint['config']\n",
    "state_dict = checkpoint['state_dict']\n",
    "model = AutoCodecND(\n",
    "    dim=3,\n",
    "    input_channels=config.input_channels,\n",
    "    J = int(np.log2(config.F)),\n",
    "    latent_dim=config.latent_dim,\n",
    "    encoder_depth = config.encoder_depth,\n",
    "    encoder_kernel_size = config.encoder_kernel_size,\n",
    "    decoder_depth = config.decoder_depth,\n",
    "    lightweight_encode = config.lightweight_encode,\n",
    "    lightweight_decode = config.lightweight_decode,\n",
    ").to(device)\n",
    "model.load_state_dict(state_dict)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89036aad-adbc-41f1-88cc-045bf9aa2296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad3d(x,p=8):\n",
    "    b, c, f, h, w = x.shape\n",
    "    t = math.ceil(f / p) * p\n",
    "    fp1 = (t - f) // 2\n",
    "    fp2 = (t - f) - fp1\n",
    "    t = math.ceil(h / p) * p\n",
    "    hp1 = (t - h) // 2\n",
    "    hp2 = (t - h) - hp1\n",
    "    t = math.ceil(w / p) * p\n",
    "    wp1 = (t - w) // 2\n",
    "    wp2 = (t - w) - wp1\n",
    "    return torch.nn.functional.pad(x, pad=(wp1, wp2, hp1, hp2, fp1, fp2), mode=\"reflect\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3e2da37-5018-4de0-8542-87ffd85f82ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean PSNR: 23.226718892426288\n"
     ]
    }
   ],
   "source": [
    "μ1 = []\n",
    "μ2 = []\n",
    "max_frames_per_chunk = 48\n",
    "\n",
    "for i_video in range(dataset['train'].num_rows):\n",
    "    sample = dataset['train'][i_video]\n",
    "    video = sample['video']\n",
    "    len_video = len(video)\n",
    "    x1080 = video.get_batch(range(len_video))\n",
    "    x1080 = einops.rearrange(x1080, 'f h w c -> c f h w')\n",
    "    x = []\n",
    "    for i_frame in range(x1080.shape[1]):\n",
    "        frame = x1080[:, i_frame]\n",
    "        x.append(pil_to_tensor(to_pil_image(frame).resize((1920, 1080))).unsqueeze(1))\n",
    "    x = torch.cat(x, dim=1).unsqueeze(0)\n",
    "    x = x / 127.5 - 1.0\n",
    "    x = x.to(device)\n",
    "    x = pad3d(x)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        z = model.encode(x)  # Latent representation\n",
    "        latent = model.quantize.compand(z).round()  # Quantized latent\n",
    "    \n",
    "    num_frames = x.shape[2]\n",
    "    num_chunks = math.ceil(num_frames / max_frames_per_chunk)\n",
    "    chunk_sizes = [max_frames_per_chunk] * (num_chunks - 1)\n",
    "    last_chunk_size = num_frames - (num_chunks - 1) * max_frames_per_chunk\n",
    "    if last_chunk_size > 0:\n",
    "        chunk_sizes.append(last_chunk_size)\n",
    "    latent_chunk_sizes = [size // 8 for size in chunk_sizes]\n",
    "    x_hat_chunks = []\n",
    "    latent_start = 0\n",
    "    with torch.no_grad():\n",
    "        for chunk_size, latent_chunk_size in zip(chunk_sizes, latent_chunk_sizes):\n",
    "            latent_end = latent_start + latent_chunk_size\n",
    "            latent_chunk = latent[:, :, latent_start:latent_end]\n",
    "            x_hat_chunk = model.decode(latent_chunk)\n",
    "            x_hat_chunks.append(x_hat_chunk)\n",
    "            latent_start = latent_end\n",
    "    x_hat = torch.cat(x_hat_chunks, dim=2)\n",
    "    x_orig_01 = x / 2 + 0.5\n",
    "    x_hat_01 = x_hat / 2 + 0.5\n",
    "    PSNR = []\n",
    "    for i_frame in range(x_orig_01.shape[2]):\n",
    "        mse = torch.nn.functional.mse_loss(x_orig_01[0, :, i_frame], x_hat_01[0, :, i_frame])\n",
    "        PSNR.append(-10 * mse.log10().item())\n",
    "    \n",
    "    μ1.append(np.mean(PSNR))\n",
    "    μ2.append(np.median(PSNR))\n",
    "\n",
    "print(f\"Mean PSNR: {np.mean(μ1)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
